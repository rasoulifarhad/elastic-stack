# This file is where you define your pipelines. You can define multiple.
# For more information on multiple pipelines, see the documentation:
#   https://www.elastic.co/guide/en/logstash/current/multiple-pipelines.html
#
# When the persistent queue feature is enabled, Logstash stores events on disk. 
# Logstash commits to disk in a mechanism called checkpointing.
# The queue itself is a set of pages. 
# There are two kinds of pages: head pages and tail pages. 
# The head page is where new events are written.There is only one head page.
# When the head page is of a certain size (see queue.page_capacity), it 
# becomes a tail page, and a new head page is created. 
# Tail pages are immutable, and the head page is append-only.
# Second, the queue records details about itself (pages, acknowledgements, etc) 
# in a separate file called a checkpoint file.
#
# When recording a checkpoint, Logstash:
#    - Calls fsync on the head page.
#    - Atomically writes to disk the current state of the queue. 
#The process of checkpointing is atomic, which means any update to the file 
# is saved if successful.
#
# If Logstash is terminated, or if there is a hardware-level failure, any data 
# that is buffered in the persistent queue, but not yet checkpointed, is lost.
#
# You can force Logstash to checkpoint more frequently by setting queue.checkpoint.writes.
# This setting specifies the maximum number of events that may be written to disk 
# before forcing a checkpoint. The default is 1024.
# 
# To ensure maximum durability and avoid data loss in the persistent queue, you can 
# set queue.checkpoint.writes: 1 to force a checkpoint after each event is written. 
#
# On disk, the queue is stored as a set of pages where each page is one file.
# Each page can be at most queue.page_capacity in size. 
# Pages are deleted (garbage collected) after all events in that page have been ACKed.
# Each page containing unprocessed events will count against the queue.max_bytes byte size.
#
# configuring persist queue:
# queue.type   --> memory           
# path.queue   --> path.data/queue
# queue.page_capacity --> 64mb
# queue.drain  --> false
# queue.max_events   --> 0 (unlimited)
# queue.max_bytes    --> 1024mb (1gb)
# queue.checkpoint.acks   --> 1024
# queue.checkpoint.writes   --> 1024
# queue.checkpoint.interval   --> 1000 milliseconds
#
- pipeline.id: dibalite
  path.config: "/usr/share/logstash/pipeline/logstash-no-ds-me.conf"
  # input → queue → filter + output
#  queue.type: persisted
  pipeline.workers: 1
#  path.queue: /var/lib/logstash/data/queue
# queue.max_bytes: 8gb
# pipeline.batch.size: 3200
# pipeline.batch.delay: 500
